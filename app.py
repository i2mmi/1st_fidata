"""
Streamlit ì•±: ì£¼ê°€ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™”
ì„¹í„°ë³„ í•„í„°ë§ ë° ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import FinanceDataReader as fdr
from datetime import datetime, timedelta
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import io
from collections import Counter

from config import setup_fonts, get_korean_font_path
from data_loader import load_tickers_from_csv, load_tickers_from_fdr, collect_stock_prices, get_stock_name
from data_processor import process_stock_data
from clustering import find_optimal_k, perform_kmeans_clustering
from sector_mapper import load_sector_mapping, get_sector_from_code, get_all_sectors_from_mapping
import warnings
warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì£¼ê°€ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# í°íŠ¸ ì„¤ì • (matplotlibìš©)
setup_fonts()

# ì„¹í„° ë¶„ë¥˜ í‚¤ì›Œë“œ (ì¢…ëª©ëª…ì— í¬í•¨ëœ í‚¤ì›Œë“œë¡œ ìë™ ë¶„ë¥˜)
SECTOR_KEYWORDS = {
    'IT/ì†Œí”„íŠ¸ì›¨ì–´': ['ë„¤ì´ë²„', 'NAVER', 'ì¹´ì¹´ì˜¤', 'í¬ë˜í”„í†¤', 'ë„·ë§ˆë¸”', 'ì—”ì”¨ì†Œí”„íŠ¸', 'í•˜ì´ë¸Œ', 'í˜ì´', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ê²Œì„', 'ì—”í„°í…Œì¸ë¨¼íŠ¸', 'ìŠ¤í€˜ì–´', 'SKìŠ¤í€˜ì–´'],
    'ë°˜ë„ì²´/ì „ì': ['ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'LGì „ì', 'SDI', 'ì „ê¸°', 'ì´ë…¸í…', 'ë°˜ë„ì²´', 'ë°˜ë„ì²´ì¥ë¹„', 'ë””ìŠ¤í”Œë ˆì´', 'ë””ìŠ¤í”Œë ˆì´', 'ì „ì'],
    'ìë™ì°¨': ['í˜„ëŒ€ì°¨', 'ê¸°ì•„', 'ëª¨ë¹„ìŠ¤', 'ê¸€ë¡œë¹„ìŠ¤', 'ì˜¤í† ', 'íƒ€ì´ì–´', 'ìë™ì°¨'],
    'ê¸ˆìœµ': ['ê¸ˆìœµ', 'ì§€ì£¼', 'ì€í–‰', 'ìƒëª…', 'ì†í•´ë³´í—˜', 'ì¹´ë“œ', 'ì¦ê¶Œ', 'íˆ¬ì', 'ìì‚°ìš´ìš©', 'ë¦¬ì¸ ', 'ìºí”¼íƒˆ'],
    'í™”í•™/ì—ë„ˆì§€': ['í™”í•™', 'ì—ë„ˆì§€', 'LGì—ë„ˆì§€', 'SKì´ë…¸ë² ì´ì…˜', 'S-Oil', 'GSì¹¼í…ìŠ¤', 'í¬ìŠ¤ì½”', 'ì„ìœ ', 'ì •ìœ ', 'LNG', 'ê°€ìŠ¤'],
    'ê±´ì„¤/ì¤‘ê³µì—…': ['ê±´ì„¤', 'ì¤‘ê³µì—…', 'ì¡°ì„ ', 'ë‘ì‚°', 'HD', 'í•œí™”ì—ì–´ë¡œ', 'ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤', 'ì¤‘ê³µì—…', 'ì—”ì§„', 'ë°œì „'],
    'ë°”ì´ì˜¤/ì œì•½': ['ë°”ì´ì˜¤', 'ì œì•½', 'ì•½í’ˆ', 'ìœ í•œì–‘í–‰', 'ì…€íŠ¸ë¦¬ì˜¨', 'ì‚¼ì„±ë°”ì´ì˜¤', 'ë…¹ì‹­ì', 'ëŒ€ì›…ì œì•½', 'ì¢…ê·¼ë‹¹', 'ë™í™”ì•½í’ˆ'],
    'ìœ í†µ/ì„œë¹„ìŠ¤': ['ì‹ ì„¸ê³„', 'ì´ë§ˆíŠ¸', 'ë¡¯ë°ì‡¼í•‘', 'GSë¦¬í…Œì¼', 'í¼ì‹œí”½', 'ì•„ëª¨ë ˆ', 'ì½”ìŠ¤ë§¥ìŠ¤', 'ìœ í†µ', 'ë°±í™”ì ', 'ë§ˆíŠ¸'],
    'í†µì‹ ': ['í…”ë ˆì½¤', 'KT', 'LGìœ í”ŒëŸ¬ìŠ¤', 'SKí…”ë ˆì½¤', 'í†µì‹ '],
    'ì² ê°•/ì†Œì¬': ['POSCO', 'í¬ìŠ¤ì½”', 'ê³ ë ¤ì•„ì—°', 'ì œì¼ì œë‹¹', 'í•œì§„', 'CJ', 'í•œí™”ì†”ë£¨ì…˜', 'LS', 'ì†Œì¬', 'ê¸ˆì†'],
    'ìš´ì†¡/ë¬¼ë¥˜': ['í•œì§„', 'í˜„ëŒ€ê¸€ë¡œë¹„ìŠ¤', 'ë¬¼ë¥˜', 'ìš´ì†¡', 'í•­ê³µ', 'í•´ìš´', 'KDB'],
    'ì „ë ¥/ê°€ìŠ¤': ['ì „ë ¥', 'ê°€ìŠ¤', 'í•œêµ­ì „ë ¥', 'í•œêµ­ê°€ìŠ¤ê³µì‚¬', 'ë„ì‹œê°€ìŠ¤'],
    'ì„¬ìœ /ì˜ë¥˜': ['í•œì„¬', 'LF', 'ì˜ë¥˜', 'ì„¬ìœ '],
}

# ì •í™•í•œ ì¢…ëª©ëª… ë§¤ì¹­ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
EXACT_MATCH = {
    'IT/ì†Œí”„íŠ¸ì›¨ì–´': ['NAVER', 'ì¹´ì¹´ì˜¤', 'í¬ë˜í”„í†¤', 'ë„·ë§ˆë¸”', 'ì—”ì”¨ì†Œí”„íŠ¸', 'í•˜ì´ë¸Œ', 'ì¹´ì¹´ì˜¤ë±…í¬', 'ì¹´ì¹´ì˜¤í˜ì´', 'SKìŠ¤í€˜ì–´'],
    'ë°˜ë„ì²´/ì „ì': ['ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'LGì „ì', 'ì‚¼ì„±SDI', 'ì‚¼ì„±ì „ê¸°', 'LGì´ë…¸í…'],
    'ìë™ì°¨': ['í˜„ëŒ€ì°¨', 'ê¸°ì•„', 'í˜„ëŒ€ëª¨ë¹„ìŠ¤'],
    'ê¸ˆìœµ': ['KBê¸ˆìœµ', 'ì‹ í•œì§€ì£¼', 'í•˜ë‚˜ê¸ˆìœµì§€ì£¼', 'ìš°ë¦¬ê¸ˆìœµì§€ì£¼', 'í•œêµ­ê¸ˆìœµì§€ì£¼', 'ë©”ë¦¬ì¸ ê¸ˆìœµì§€ì£¼', 'BNKê¸ˆìœµì§€ì£¼', 'JBê¸ˆìœµì§€ì£¼'],
    'í™”í•™/ì—ë„ˆì§€': ['LGí™”í•™', 'SKì´ë…¸ë² ì´ì…˜', 'S-Oil', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'í¬ìŠ¤ì½”í“¨ì²˜ì— '],
    'ê±´ì„¤/ì¤‘ê³µì—…': ['ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°', 'HDí˜„ëŒ€ì¤‘ê³µì—…', 'HDí•œêµ­ì¡°ì„ í•´ì–‘', 'í˜„ëŒ€ê±´ì„¤', 'í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤'],
    'ë°”ì´ì˜¤/ì œì•½': ['ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', 'ì…€íŠ¸ë¦¬ì˜¨', 'SKë°”ì´ì˜¤íŒœ', 'í•œë¯¸ì•½í’ˆ', 'ìœ í•œì–‘í–‰'],
    'ìœ í†µ/ì„œë¹„ìŠ¤': ['ì•„ëª¨ë ˆí¼ì‹œí”½', 'ì‹ ì„¸ê³„', 'ì´ë§ˆíŠ¸', 'ë¡¯ë°ì‡¼í•‘', 'GSë¦¬í…Œì¼'],
    'í†µì‹ ': ['SKí…”ë ˆì½¤', 'KT', 'LGìœ í”ŒëŸ¬ìŠ¤'],
    'ì² ê°•/ì†Œì¬': ['POSCOí™€ë”©ìŠ¤', 'ê³ ë ¤ì•„ì—°', 'í•œêµ­íƒ€ì´ì–´ì•¤í…Œí¬ë†€ë¡œì§€'],
}


def get_sector(stock_name, sector_keywords=None, exact_match=None):
    """
    ì¢…ëª©ëª…ìœ¼ë¡œë¶€í„° ì„¹í„° ì°¾ê¸° (ê°œì„ ëœ ë²„ì „)
    
    Parameters:
    -----------
    stock_name : str
        ì¢…ëª©ëª…
    sector_keywords : dict
        ì„¹í„°ë³„ í‚¤ì›Œë“œ ë”•ì…”ë„ˆë¦¬
    exact_match : dict
        ì •í™•í•œ ì¢…ëª©ëª… ë§¤ì¹­ ë”•ì…”ë„ˆë¦¬
    
    Returns:
    --------
    sector : str
        ì„¹í„°ëª…
    """
    if exact_match is None:
        exact_match = EXACT_MATCH
    if sector_keywords is None:
        sector_keywords = SECTOR_KEYWORDS
    
    # 1ë‹¨ê³„: ì •í™•í•œ ì¢…ëª©ëª… ë§¤ì¹­ (ìš°ì„ ìˆœìœ„)
    for sector, stocks in exact_match.items():
        if stock_name in stocks:
            return sector
    
    # 2ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­
    for sector, keywords in sector_keywords.items():
        for keyword in keywords:
            if keyword in stock_name:
                return sector
    
    return 'ê¸°íƒ€'


def find_optimal_k_streamlit(movements, max_k=10, min_k=2):
    """Streamlitìš© ìµœì  K íƒìƒ‰ í•¨ìˆ˜ (Plotly ì‚¬ìš©)"""
    from sklearn.preprocessing import Normalizer
    from sklearn.cluster import KMeans
    from sklearn.metrics import silhouette_score
    import numpy as np
    
    k_range = range(min_k, max_k + 1)
    inertias = []
    silhouette_scores = []
    
    normalizer = Normalizer()
    normalized_data = normalizer.fit_transform(movements)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, k in enumerate(k_range):
        status_text.text(f"K={k} í…ŒìŠ¤íŠ¸ ì¤‘...")
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels = kmeans.fit_predict(normalized_data)
        
        inertias.append(kmeans.inertia_)
        
        if len(movements) > 100:
            sample_indices = np.random.choice(len(movements), size=min(100, len(movements)), replace=False)
            sample_data = normalized_data[sample_indices]
            sample_labels = labels[sample_indices]
            silhouette_avg = silhouette_score(sample_data, sample_labels)
        else:
            silhouette_avg = silhouette_score(normalized_data, labels)
        silhouette_scores.append(silhouette_avg)
        
        progress_bar.progress((idx + 1) / len(k_range))
    
    results_df = pd.DataFrame({
        'K': list(k_range),
        'Inertia': inertias,
        'Silhouette_Score': silhouette_scores
    })
    
    # ìµœì  K ê²°ì •
    optimal_k_silhouette = int(results_df.loc[results_df['Silhouette_Score'].idxmax(), 'K'])
    
    results_df['Inertia_Change'] = results_df['Inertia'].diff().abs()
    results_df['Inertia_Change_Rate'] = results_df['Inertia_Change'].pct_change().abs()
    
    if len(results_df) > 2:
        mean_change_rate = results_df['Inertia_Change_Rate'].mean()
        elbow_candidates = results_df[results_df['Inertia_Change_Rate'] < mean_change_rate]
        if not elbow_candidates.empty:
            optimal_k_elbow = int(elbow_candidates.iloc[0]['K'])
        else:
            optimal_k_elbow = int(results_df.loc[results_df['Inertia_Change_Rate'].idxmin(), 'K'])
    else:
        optimal_k_elbow = min_k
    
    optimal_k = int(np.round((optimal_k_silhouette + optimal_k_elbow) / 2))
    
    # Plotly ì‹œê°í™”
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('Elbow Method', 'Silhouette Score'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # Elbow Method
    fig.add_trace(
        go.Scatter(
            x=results_df['K'],
            y=results_df['Inertia'],
            mode='lines+markers',
            name='Inertia',
            line=dict(width=3),
            marker=dict(size=10)
        ),
        row=1, col=1
    )
    
    fig.add_vline(
        x=optimal_k_elbow, 
        line_dash="dash", 
        line_color="red",
        annotation_text=f"Elbow K={optimal_k_elbow}",
        row=1, col=1
    )
    
    # Silhouette Score
    colors_bar = ['red' if k == optimal_k_silhouette else 'steelblue' for k in results_df['K']]
    fig.add_trace(
        go.Bar(
            x=results_df['K'],
            y=results_df['Silhouette_Score'],
            name='Silhouette Score',
            marker_color=colors_bar
        ),
        row=1, col=2
    )
    
    fig.add_vline(
        x=optimal_k_silhouette,
        line_dash="dash",
        line_color="red",
        annotation_text=f"Optimal K={optimal_k_silhouette}",
        row=1, col=2
    )
    
    fig.update_xaxes(title_text="í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (K)", row=1, col=1)
    fig.update_xaxes(title_text="í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (K)", row=1, col=2)
    fig.update_yaxes(title_text="Inertia", row=1, col=1)
    fig.update_yaxes(title_text="Silhouette Score", row=1, col=2)
    
    fig.update_layout(
        height=500,
        showlegend=False,
        title_text="ìµœì  K ê°’ íƒìƒ‰ ê²°ê³¼"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    status_text.empty()
    progress_bar.empty()
    
    st.info(f"**Elbow Method ì¶”ì²œ K**: {optimal_k_elbow}  |  **Silhouette Score ìµœì  K**: {optimal_k_silhouette}  |  **ìµœì¢… ì¶”ì²œ K**: {optimal_k}")
    
    return optimal_k, results_df


@st.cache_data
def load_and_process_data(csv_path, limit, years):
    """ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬ (ìºì‹±)"""
    # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘
    if csv_path:
        tickers, names = load_tickers_from_csv(csv_path)
        if tickers is None:
            return None, None, None, 0
        total_tickers = len(tickers)
    else:
        tickers, names = load_tickers_from_fdr(limit=limit)
        total_tickers = len(tickers)
    
    if limit:
        tickers = tickers[:limit]
        total_tickers = len(tickers)
    
    # ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ (ì½”ìŠ¤í”¼ ì¢…ëª©ì´ë¯€ë¡œ ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë‚®ì¶¤)
    stock_data = collect_stock_prices(tickers, years=years, min_data_points=50)
    if stock_data is None:
        return None, None, None, total_tickers
    
    # ë¡œê·¸ ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
    movements = process_stock_data(stock_data)
    if movements is None or movements.empty:
        return None, None, None, total_tickers
    
    return movements, names, stock_data, total_tickers


def get_stock_code_from_name(company_name, sector_names_dict):
    """
    íšŒì‚¬ëª…ìœ¼ë¡œ ì¢…ëª© ì½”ë“œ ì°¾ê¸°
    
    Parameters:
    -----------
    company_name : str
        íšŒì‚¬ëª…
    sector_names_dict : dict
        {code: name} í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
    
    Returns:
    --------
    str or None
        ì¢…ëª© ì½”ë“œ, ì—†ìœ¼ë©´ None
    """
    for code, name in sector_names_dict.items():
        if name == company_name:
            return code
    return None


def get_stock_price_chart(stock_code, company_name, years=1):
    """
    ì¢…ëª© ì½”ë“œë¡œ 1ë…„ì¹˜ ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ê·¸ë˜í”„ë¡œ í‘œì‹œ
    
    Parameters:
    -----------
    stock_code : str
        ì¢…ëª© ì½”ë“œ (ì˜ˆ: '005930')
    company_name : str
        íšŒì‚¬ëª…
    years : float
        ê°€ì ¸ì˜¬ ê¸°ê°„ (ë…„)
    
    Returns:
    --------
    plotly.graph_objects.Figure or None
        ì£¼ê°€ ì°¨íŠ¸, ì‹¤íŒ¨í•˜ë©´ None
    """
    try:
        from datetime import datetime, timedelta
        
        start_date = (datetime.now() - timedelta(days=365 * years)).strftime('%Y-%m-%d')
        end_date = datetime.now().strftime('%Y-%m-%d')
        
        df = fdr.DataReader(stock_code, start_date, end_date)
        
        if df is None or df.empty:
            return None
        
        # Plotlyë¡œ ì£¼ê°€ ì°¨íŠ¸ ìƒì„±
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=df.index,
            y=df['Close'],
            mode='lines',
            name='ì¢…ê°€',
            line=dict(color='blue', width=2),
            hovertemplate='ë‚ ì§œ: %{x}<br>ì¢…ê°€: %{y:,.0f}ì›<extra></extra>'
        ))
        
        fig.update_layout(
            title=f'{company_name} ({stock_code}) ì£¼ê°€ ì¶”ì´ (ìµœê·¼ {years}ë…„)',
            xaxis_title='ë‚ ì§œ',
            yaxis_title='ì¢…ê°€ (ì›)',
            hovermode='x unified',
            height=500,
            showlegend=True
        )
        
        return fig
        
    except Exception as e:
        st.error(f"ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None


@st.cache_data
def load_and_process_score_data(csv_path='data/score.csv'):
    """
    score.csv íŒŒì¼ì—ì„œ PCA ê²°ê³¼ ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
    
    Parameters:
    -----------
    csv_path : str
        score.csv íŒŒì¼ ê²½ë¡œ
    
    Returns:
    --------
    data : pd.DataFrame
        Company_Name, PCA1, PCA2 ì»¬ëŸ¼ì„ ê°€ì§„ DataFrame
    pca_data : np.array
        PCA ì¢Œí‘œ (2ì°¨ì›)
    """
    try:
        df = pd.read_csv(csv_path)
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df = df.rename(columns={'0': 'PCA1', '1': 'PCA2'})
        pca_data = df[['PCA1', 'PCA2']].values
        return df, pca_data
    except Exception as e:
        st.error(f"âŒ score.csv ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


def perform_clustering_on_pca_data(pca_data, n_clusters=4):
    """
    PCA ë°ì´í„°ì— ëŒ€í•´ K-means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    
    Parameters:
    -----------
    pca_data : np.array
        PCA ì¢Œí‘œ (N x 2)
    n_clusters : int
        í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
    
    Returns:
    --------
    labels : np.array
        í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”
    """
    from sklearn.cluster import KMeans
    
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    labels = kmeans.fit_predict(pca_data)
    
    return labels


def create_interactive_plot_from_pca(results, selected_sectors=None, selected_clusters=None, search_term=None, n_clusters=4):
    """
    score.csv ë°ì´í„°ìš© ê°„ë‹¨í•œ Plotly ì‹œê°í™” (test_clustering_score.py ë°©ì‹)
    
    Parameters:
    -----------
    results : pd.DataFrame
        ê²°ê³¼ ë°ì´í„° (Name, PCA1, PCA2, Cluster, Sector í¬í•¨)
    selected_sectors : list
        ì„ íƒëœ ì„¹í„° ë¦¬ìŠ¤íŠ¸
    selected_clusters : list
        ì„ íƒëœ í´ëŸ¬ìŠ¤í„° ë¦¬ìŠ¤íŠ¸
    search_term : str
        ê²€ìƒ‰ì–´
    n_clusters : int
        í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
    """
    # í•„í„°ë§
    filtered_results = results.copy()
    
    if selected_sectors and 'ì „ì²´' not in selected_sectors:
        filtered_results = filtered_results[
            filtered_results['Sector'].isin(selected_sectors)
        ]
    
    if selected_clusters:
        filtered_results = filtered_results[
            filtered_results['Cluster'].isin(selected_clusters)
        ]
    
    if search_term:
        # Name ë˜ëŠ” Company_Name ì»¬ëŸ¼ ì‚¬ìš©
        name_col = 'Company_Name' if 'Company_Name' in filtered_results.columns else 'Name'
        filtered_results = filtered_results[
            filtered_results[name_col].str.contains(search_term, case=False, na=False)
        ]
    
    # Plotlyë¡œ ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™” (test_clustering_score.py ë°©ì‹)
    # Name ë˜ëŠ” Company_Name ì»¬ëŸ¼ ì‚¬ìš©
    name_col = 'Company_Name' if 'Company_Name' in filtered_results.columns else 'Name'
    
    # hover_dataì—ì„œ Clusterë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ (ìˆœì„œ ë³´ì¥ì„ ìœ„í•´)
    fig = px.scatter(
        filtered_results,
        x='PCA1',
        y='PCA2',
        color='Cluster',
        hover_name=name_col,  # ì ì— ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ë©´ ê¸°ì—…ëª…ì´ ì œëª©ìœ¼ë¡œ í‘œì‹œ
        hover_data={
            'Sector': True,
            'PCA1': ':.3f',
            'PCA2': ':.3f',
            'Cluster': True,  # í´ëŸ¬ìŠ¤í„° ê°’ í¬í•¨
            name_col: False  # hover_nameìœ¼ë¡œ ì´ë¯¸ í‘œì‹œë˜ë¯€ë¡œ ì¤‘ë³µ ì œê±°
        },
        title=f'K-means í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ (K={n_clusters})',
        labels={
            'PCA1': 'PCA 1ì°¨ì› (Xì¶•)', 
            'PCA2': 'PCA 2ì°¨ì› (Yì¶•)', 
            'Cluster': 'í´ëŸ¬ìŠ¤í„°', 
            'Sector': 'ì„¹í„°'
        }
    )
    
    # ì»¤ìŠ¤í…€ hover í…œí”Œë¦¿ìœ¼ë¡œ ìƒì„¸ ì •ë³´ í‘œì‹œ
    # customdata êµ¬ì¡° í™•ì¸ ê²°ê³¼: [Sector, Cluster, Name]
    # x, y ì¢Œí‘œëŠ” %{x}, %{y}ë¡œ ì§ì ‘ ì°¸ì¡° ê°€ëŠ¥
    # í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ëŠ” customdata[1]ì— ìˆìŒ
    fig.update_traces(
        marker=dict(size=10, opacity=0.7, line=dict(width=0.5, color='white')),
        hovertemplate='<b>%{hovertext}</b><br>' +
                      'ì„¹í„°: %{customdata[0]}<br>' +
                      'PCA1: %{x:.3f}<br>' +
                      'PCA2: %{y:.3f}<br>' +
                      'í´ëŸ¬ìŠ¤í„°: %{customdata[1]}<br>' +
                      '<extra></extra>'
    )
    
    fig.update_layout(
        width=1000,
        height=700,
        font=dict(size=12)
    )
    
    return fig


def create_interactive_plot(results, movements=None, pipeline=None, selected_sectors=None, selected_clusters=None, search_term=None, use_pca_coords=False):
    """
    ì¸í„°ë™í‹°ë¸Œ Plotly ì°¨íŠ¸ ìƒì„± (ì£¼ê°€ ë°ì´í„°ìš©)
    
    Parameters:
    -----------
    results : pd.DataFrame
        ê²°ê³¼ ë°ì´í„° (Code, Name, Cluster, Sector í¬í•¨)
    movements : pd.DataFrame or None
        ì£¼ê°€ ë°ì´í„° (use_pca_coords=Falseì¼ ë•Œ ì‚¬ìš©)
    pipeline : Pipeline or None
        í•™ìŠµëœ íŒŒì´í”„ë¼ì¸ (use_pca_coords=Falseì¼ ë•Œ ì‚¬ìš©)
    selected_sectors : list
        ì„ íƒëœ ì„¹í„° ë¦¬ìŠ¤íŠ¸
    selected_clusters : list
        ì„ íƒëœ í´ëŸ¬ìŠ¤í„° ë¦¬ìŠ¤íŠ¸
    search_term : str
        ê²€ìƒ‰ì–´
    use_pca_coords : bool
        Trueë©´ resultsì— ì´ë¯¸ PCA ì¢Œí‘œê°€ ìˆìŒ (PCA1, PCA2 ì»¬ëŸ¼)
    """
    from sklearn.decomposition import PCA
    from sklearn.preprocessing import Normalizer
    
    # ì£¼ê°€ ë°ì´í„°: PCA ê³„ì‚° í•„ìš”
    if movements is None:
        st.error("âŒ movements ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return None, None
    
    normalizer = Normalizer()
    normalized_data = normalizer.fit_transform(movements)
    pca = PCA(n_components=2)
    reduced_data = pca.fit_transform(normalized_data)
    
    results['x'] = reduced_data[:, 0]
    results['y'] = reduced_data[:, 1]
    
    # í•„í„°ë§
    filtered_results = results.copy()
    
    if selected_sectors and 'ì „ì²´' not in selected_sectors:
        filtered_results = filtered_results[
            filtered_results['Sector'].isin(selected_sectors)
        ]
    
    if selected_clusters:
        filtered_results = filtered_results[
            filtered_results['Cluster'].isin(selected_clusters)
        ]
    
    if search_term:
        name_match = filtered_results['Name'].str.contains(search_term, case=False, na=False)
        # Code ì»¬ëŸ¼ì´ ìˆê³  ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ê²€ìƒ‰
        if 'Code' in filtered_results.columns:
            # Code ì»¬ëŸ¼ì´ ë¹„ì–´ìˆì§€ ì•Šì€ í–‰ë§Œ ê²€ìƒ‰
            code_not_empty = filtered_results['Code'].astype(str).str.strip() != ''
            code_match = filtered_results['Code'].astype(str).str.contains(search_term, case=False, na=False)
            filtered_results = filtered_results[name_match | (code_not_empty & code_match)]
        else:
            filtered_results = filtered_results[name_match]
    
    # Plotly ì‹œê°í™”
    fig = go.Figure()
    
    # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ìƒ‰ìƒ ì§€ì •
    colors = px.colors.qualitative.Set3
    n_clusters = results['Cluster'].nunique()
    
    for cluster_id in sorted(results['Cluster'].unique()):
        cluster_data = filtered_results[filtered_results['Cluster'] == cluster_id]
        
        if len(cluster_data) > 0:
            color = colors[cluster_id % len(colors)]
            
            # í˜¸ë²„ ì •ë³´ ì¤€ë¹„
            hover_texts = []
            for idx, row in cluster_data.iterrows():
                hover_text = f"<b>{row['Name']}</b><br>"
                if 'Code' in row and row['Code'] and str(row['Code']).strip():
                    hover_text += f"ì½”ë“œ: {row['Code']}<br>"
                hover_text += f"í´ëŸ¬ìŠ¤í„°: {cluster_id}<br>"
                hover_text += f"ì„¹í„°: {row['Sector']}<br>"
                hover_text += f"X: {row['x']:.3f}<br>"
                hover_text += f"Y: {row['y']:.3f}"
                hover_texts.append(hover_text)
            
            fig.add_trace(go.Scatter(
                x=cluster_data['x'],
                y=cluster_data['y'],
                mode='markers',
                name=f'í´ëŸ¬ìŠ¤í„° {cluster_id} ({len(cluster_data)}ê°œ)',
                text=cluster_data['Name'],
                textposition='middle center',
                hovertext=hover_texts,
                hovertemplate='%{hovertext}<extra></extra>',
                marker=dict(
                    size=15,
                    color=color,
                    line=dict(width=1.5, color='black'),
                    opacity=0.8
                )
            ))
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title={
            'text': f'ğŸ“Š ì£¼ê°€ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™” (í‘œì‹œ: {len(filtered_results)}ê°œ / ì „ì²´: {len(results)}ê°œ)',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 22, 'color': 'darkblue'}
        },
        xaxis_title=f'PCA Component 1 (ì„¤ëª…ë ¥: {pca.explained_variance_ratio_[0]*100:.1f}%)',
        yaxis_title=f'PCA Component 2 (ì„¤ëª…ë ¥: {pca.explained_variance_ratio_[1]*100:.1f}%)',
        hovermode='closest',
        height=750,
        showlegend=True,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.02,
            bgcolor="rgba(255,255,255,0.8)",
            bordercolor="black",
            borderwidth=1
        ),
        plot_bgcolor='rgba(240,240,240,0.5)',
        paper_bgcolor='white'
    )
    
    # ê·¸ë¦¬ë“œ ì¶”ê°€
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
    
    return fig, pca


def create_wordcloud(sector_counts):
    """
    ì„¹í„° ë¹ˆë„ìˆ˜ë¡œ ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„±
    
    Parameters:
    -----------
    sector_counts : pd.Series
        ì„¹í„°ë³„ ë¹ˆë„ìˆ˜ (value_counts ê²°ê³¼)
    
    Returns:
    --------
    wordcloud_image : bytes
        ì›Œë“œ í´ë¼ìš°ë“œ ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°
    """
    # ì„¹í„°ë³„ ë¹ˆë„ìˆ˜ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    word_freq = sector_counts.to_dict()
    
    # í•œêµ­ì–´ í°íŠ¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    font_path = get_korean_font_path()
    
    # ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„±
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        font_path=font_path,  # í•œêµ­ì–´ í°íŠ¸ ì‚¬ìš©
        colormap='Set3',
        max_words=50,
        relative_scaling=0.5,
        min_font_size=10,
        max_font_size=60
    ).generate_from_frequencies(word_freq)
    
    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    img_buffer = io.BytesIO()
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.tight_layout(pad=0)
    plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=150)
    img_buffer.seek(0)
    plt.close()
    
    return img_buffer


def main():
    st.title("ğŸ“Š ì£¼ê°€ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        st.info("ğŸ“ ë°ì´í„° ì†ŒìŠ¤: `data/score.csv` (PCA ê²°ê³¼ ë°ì´í„°)")
        
        # í´ëŸ¬ìŠ¤í„°ë§ ì„¤ì •
        st.subheader("í´ëŸ¬ìŠ¤í„°ë§ ì„¤ì •")
        find_optimal = st.checkbox("ìµœì  K ìë™ íƒìƒ‰", value=False)
        
        if not find_optimal:
            n_clusters = st.slider("í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (K)", 2, 15, 4)
        else:
            max_k = st.slider("ìµœëŒ€ K ê°’", 5, 15, 10)
            n_clusters = 4  # ì´ˆê¸°ê°’
        
        # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
        analyze_button = st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)
    
    # ë©”ì¸ ì˜ì—­
    if analyze_button:
        with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # score.csv ë°ì´í„° ì‚¬ìš©
                score_data, pca_data = load_and_process_score_data('data/score.csv')
                if score_data is None or pca_data is None:
                    st.error("âŒ score.csv ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return
                
                st.success(f"âœ… {len(score_data)}ê°œ ê¸°ì—… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                
                # ìµœì  K íƒìƒ‰ (ì„ íƒì‚¬í•­)
                if find_optimal:
                    st.subheader("ğŸ” ìµœì  K ê°’ íƒìƒ‰")
                    from sklearn.metrics import silhouette_score
                    from sklearn.cluster import KMeans
                    import tqdm
                    
                    k_range = range(2, max_k + 1)
                    silhouette_scores = []
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, k in enumerate(k_range):
                        status_text.text(f"K={k} í…ŒìŠ¤íŠ¸ ì¤‘...")
                        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                        labels = kmeans.fit_predict(pca_data)
                        
                        if len(pca_data) > 1000:
                            # ë°ì´í„°ê°€ ë§ìœ¼ë©´ ìƒ˜í”Œë§
                            sample_size = min(1000, len(pca_data))
                            sample_indices = np.random.choice(len(pca_data), size=sample_size, replace=False)
                            sample_data = pca_data[sample_indices]
                            sample_labels = labels[sample_indices]
                            silhouette_avg = silhouette_score(sample_data, sample_labels)
                        else:
                            silhouette_avg = silhouette_score(pca_data, labels)
                        silhouette_scores.append(silhouette_avg)
                        progress_bar.progress((idx + 1) / len(k_range))
                    
                    optimal_k_idx = np.argmax(silhouette_scores)
                    optimal_k = list(k_range)[optimal_k_idx]
                    n_clusters = optimal_k
                    
                    progress_bar.empty()
                    status_text.empty()
                    st.success(f"âœ¨ ìµœì  K ê°’: {optimal_k}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
                with st.spinner("í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                    labels = perform_clustering_on_pca_data(pca_data, n_clusters=n_clusters)
                
                # ì„¹í„° ì •ë³´ ë¡œë“œ
                sector_mapping_dict, sector_names_dict = load_sector_mapping('data/kospi_code.csv')
                
                # ê²°ê³¼ ì •ë¦¬
                sectors = []
                for name in score_data['Company_Name']:
                    # ì´ë¦„ìœ¼ë¡œ ì„¹í„° ì°¾ê¸°
                    sector = 'ê¸°íƒ€'
                    for code, stock_name in sector_names_dict.items():
                        if name == stock_name:
                            sector = get_sector_from_code(code, sector_mapping_dict)
                            break
                    sectors.append(sector)
                
                results = pd.DataFrame({
                    'Name': score_data['Company_Name'],
                    'PCA1': score_data['PCA1'],
                    'PCA2': score_data['PCA2'],
                    'Cluster': labels,
                    'Sector': sectors
                })
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state['results'] = results
                st.session_state['pca_data'] = pca_data
                st.session_state['n_clusters'] = n_clusters
                st.session_state['sector_names_dict'] = sector_names_dict
                
                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! {len(results)}ê°œ ì¢…ëª©ì´ {n_clusters}ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.exception(e)
                return
    
    # ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‹œê°í™”
    if 'results' in st.session_state:
        results = st.session_state['results']
        
        st.markdown("---")
        
        # í•„í„°ë§ ì„¹ì…˜
        col1, col2, col3 = st.columns([2, 2, 2])
        
        with col1:
            st.subheader("ğŸ” í•„í„°ë§")
            all_sectors = ['ì „ì²´'] + sorted(results['Sector'].unique().tolist())
            selected_sectors = st.multiselect(
                "ì„¹í„° ì„ íƒ",
                all_sectors,
                default=['ì „ì²´'],
                help="í‘œì‹œí•  ì„¹í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col2:
            st.subheader("ğŸ“Š í´ëŸ¬ìŠ¤í„°")
            all_clusters = sorted(results['Cluster'].unique().tolist())
            selected_clusters = st.multiselect(
                "í´ëŸ¬ìŠ¤í„° ì„ íƒ",
                all_clusters,
                default=all_clusters,
                help="í‘œì‹œí•  í´ëŸ¬ìŠ¤í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col3:
            st.subheader("ğŸ” ê²€ìƒ‰")
            search_term = st.text_input(
                "ì¢…ëª©ëª… ê²€ìƒ‰",
                "",
                help="ì¢…ëª©ëª…ìœ¼ë¡œ ê²€ìƒ‰í•˜ì„¸ìš”"
            )
        
        # í†µê³„ ì •ë³´
        st.markdown("---")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì „ì²´ ì¢…ëª© ìˆ˜", len(results))
        with col2:
            st.metric("í´ëŸ¬ìŠ¤í„° ìˆ˜", results['Cluster'].nunique())
        with col3:
            st.metric("ì„¹í„° ìˆ˜", results['Sector'].nunique())
        with col4:
            # í•„í„°ë§ëœ ê²°ê³¼ ê°œìˆ˜ ê³„ì‚°
            filtered_df = results.copy()
            if selected_sectors and 'ì „ì²´' not in selected_sectors:
                filtered_df = filtered_df[filtered_df['Sector'].isin(selected_sectors)]
            if selected_clusters:
                filtered_df = filtered_df[filtered_df['Cluster'].isin(selected_clusters)]
            if search_term:
                # Name ë˜ëŠ” Company_Name ì»¬ëŸ¼ ì‚¬ìš©
                name_col = 'Company_Name' if 'Company_Name' in filtered_df.columns else 'Name'
                name_match = filtered_df[name_col].str.contains(search_term, case=False, na=False)
                # Code ì»¬ëŸ¼ì´ ìˆê³  ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ê²€ìƒ‰
                if 'Code' in filtered_df.columns:
                    code_not_empty = filtered_df['Code'].astype(str).str.strip() != ''
                    code_match = filtered_df['Code'].astype(str).str.contains(search_term, case=False, na=False)
                    filtered_df = filtered_df[name_match | (code_not_empty & code_match)]
                else:
                    filtered_df = filtered_df[name_match]
            st.metric("í‘œì‹œ ì¤‘", len(filtered_df))
        
        # ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸
        st.markdown("---")
        st.subheader("ğŸ“ˆ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™”")
        
        # score.csv ë°ì´í„°: ê°„ë‹¨í•œ ì‹œê°í™” (test_clustering_score.py ë°©ì‹)
        n_clusters = st.session_state.get('n_clusters', 4)
        fig = create_interactive_plot_from_pca(
            results, 
            selected_sectors, 
            selected_clusters, 
            search_term,
            n_clusters=n_clusters
        )
        
        # ì  í´ë¦­ ì´ë²¤íŠ¸ ì²˜ë¦¬ (Streamlit 1.31.0+)
        try:
            selected_point = st.plotly_chart(fig, use_container_width=True, on_select="rerun", key="pca_chart")
            
            # ì„ íƒëœ ì ì´ ìˆìœ¼ë©´ ì£¼ê°€ ì°¨íŠ¸ í‘œì‹œ
            if selected_point and 'selection' in selected_point and selected_point['selection'].get('points'):
                point_data = selected_point['selection']['points'][0]
                selected_company = None
                
                # ì„ íƒëœ ì ì—ì„œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
                if 'hovertext' in point_data:
                    selected_company = point_data['hovertext']
                elif 'customdata' in point_data:
                    customdata = point_data['customdata']
                    if isinstance(customdata, list) and len(customdata) > 0:
                        selected_company = customdata[0]
                
                if selected_company:
                    # íšŒì‚¬ëª…ìœ¼ë¡œ ì¢…ëª© ì½”ë“œ ì°¾ê¸°
                    sector_names_dict = st.session_state.get('sector_names_dict', {})
                    if not sector_names_dict:
                        _, sector_names_dict = load_sector_mapping('data/kospi_code.csv')
                        st.session_state['sector_names_dict'] = sector_names_dict
                    
                    stock_code = get_stock_code_from_name(selected_company, sector_names_dict)
                    
                    if stock_code:
                        st.markdown("---")
                        st.subheader(f"ğŸ“ˆ {selected_company} ì£¼ê°€ ì¶”ì´")
                        
                        with st.spinner("ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                            price_fig = get_stock_price_chart(stock_code, selected_company, years=1)
                            if price_fig:
                                st.plotly_chart(price_fig, use_container_width=True)
                            else:
                                st.warning(f"âš ï¸ {selected_company}ì˜ ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ {selected_company}ì˜ ì¢…ëª© ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except TypeError:
            # on_selectê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë²„ì „ì—ì„œëŠ” ê¸°ë³¸ ë™ì‘
            st.plotly_chart(fig, use_container_width=True)
            st.info("ğŸ’¡ ì ì„ í´ë¦­í•˜ì—¬ ì£¼ê°€ ì°¨íŠ¸ë¥¼ ë³´ë ¤ë©´ Streamlit 1.31.0 ì´ìƒ ë²„ì „ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # í´ëŸ¬ìŠ¤í„°ë³„ ì„¹í„° ë¶„í¬ (ì›Œë“œ í´ë¼ìš°ë“œ)
        st.markdown("---")
        st.subheader("ğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ ì„¹í„° ë¶„í¬")
        
        selected_cluster_for_wordcloud = st.selectbox(
            "ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ë³¼ í´ëŸ¬ìŠ¤í„° ì„ íƒ",
            sorted(results['Cluster'].unique().tolist()),
            key="wordcloud_cluster"
        )
        
        cluster_data = results[results['Cluster'] == selected_cluster_for_wordcloud]
        sector_counts = cluster_data['Sector'].value_counts()
        
        if len(sector_counts) > 0:
            col1, col2 = st.columns([2, 1])
            with col1:
                wordcloud_img = create_wordcloud(sector_counts)
                st.image(wordcloud_img, use_container_width=True)
            with col2:
                st.write("**ì„¹í„°ë³„ ê°œìˆ˜**")
                st.dataframe(
                    sector_counts.reset_index().rename(columns={'index': 'ì„¹í„°', 'Sector': 'ê°œìˆ˜'}),
                    use_container_width=True,
                    height=400
                )
        else:
            st.info("í‘œì‹œí•  ì„¹í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.markdown("---")
        csv = results.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
            data=csv,
            file_name=f"clustering_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    else:
        # ì´ˆê¸° í™”ë©´
        st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ í•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        
        st.markdown("""
        ### ğŸ“– ì‚¬ìš© ë°©ë²•
        
        1. **ë°ì´í„° ì†ŒìŠ¤**
           - `data/score.csv` íŒŒì¼ì˜ PCA ê²°ê³¼ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤
        
        2. **í´ëŸ¬ìŠ¤í„°ë§ ì„¤ì •**
           - ìµœì  K ìë™ íƒìƒ‰ ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ K ê°’ ì§€ì •
        
        3. **ë¶„ì„ ì‹œì‘**
           - ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤
        
        4. **í•„í„°ë§ ë° íƒìƒ‰**
           - ì„¹í„°ë³„, í´ëŸ¬ìŠ¤í„°ë³„ë¡œ í•„í„°ë§ ê°€ëŠ¥
           - ì¢…ëª©ëª…ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥
           - ì¸í„°ë™í‹°ë¸Œ ì°¨íŠ¸ì—ì„œ ì ì„ í´ë¦­í•˜ë©´ í•´ë‹¹ ê¸°ì—…ì˜ ì£¼ê°€ ì¶”ì´ í™•ì¸
           - ì›Œë“œ í´ë¼ìš°ë“œë¡œ í´ëŸ¬ìŠ¤í„° ë‚´ ì„¹í„° ë¶„í¬ í™•ì¸
        """)


if __name__ == "__main__":
    main()

